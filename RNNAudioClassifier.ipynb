{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2FHkQYvkU4Zb",
    "outputId": "0e6b869d-76ca-4d51-a939-7fbff3316205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 65536)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "genres = ['blues','metal','country','hiphop','jazz','classical']\n",
    "\n",
    "N=len(genres)\n",
    "\n",
    "wavlist = []\n",
    "labels = []\n",
    "\n",
    "# blues=0,metal=1,country=2,hiphop=3\n",
    "for i,genre in enumerate(genres):\n",
    "    files = os.listdir('/content/drive/My Drive/dataset/genres/'+genre)\n",
    "    for f in files:\n",
    "        filename = '/content/drive/My Drive/dataset/genres/'+genre+'/'+f\n",
    "        count,data = wavfile.read(filename)\n",
    "        \n",
    "        if i % 3 == 0:                  \n",
    "            # Here, I am downsampling the data by a factor of 8, and keeping only the first 65536 features,\n",
    "            # roughly 30 sec\n",
    "            wavlist.append(data[:2**19:8]/2**15)\n",
    "            labels.append(i)\n",
    "       \n",
    "y = np.array(labels)\n",
    "X = np.vstack(wavlist)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VazsjLqVU4Z9",
    "outputId": "a5ee33d5-0fbf-4175-be5e-18179a844bbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 65536, 1) (160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Training/test set split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "\n",
    "X_train = X_train.reshape((*X_train.shape,1))\n",
    "X_test = X_test.reshape((*X_test.shape,1))\n",
    "\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CBwT87n-U4aO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "\n",
    "X_train = X_train.to(torch.float32)\n",
    "\n",
    "#Pytorch expects channels first, so reshape\n",
    "X_train = X_train.reshape(-1,1,2**16)\n",
    "X_test = X_test.to(torch.float32)\n",
    "X_test = X_test.reshape(-1,1,2**16)\n",
    "y_train = y_train.to(torch.long)\n",
    "y_test = y_test.to(torch.long)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "training_data = TensorDataset(X_train,y_train)\n",
    "test_data = TensorDataset(X_test,y_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "batch_size = 32\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WKEwNnu8aZYu",
    "outputId": "9a681aff-ed05-42a0-c417-1c4287e7ccc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 1, 65536]) torch.Size([160])\n",
      "torch.Size([40, 1, 65536]) torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6p2nivuheQof"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# class definition\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=6, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # setup LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        # setup output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (\n",
    "            torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "            torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "       \n",
    "        lstm_out, hidden = self.lstm(input)\n",
    "        logits = self.linear(lstm_out[-1])\n",
    "        genre_scores = F.log_softmax(logits, dim=1)\n",
    "        return genre_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "EdUfESDXU4bR",
    "outputId": "24894179-9424-4443-f508-45e6ebfdc50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7012228965759277 51.875 42.5\n",
      "10 0.6996627449989319 48.125 57.5\n",
      "20 0.6780390739440918 48.125 57.5\n",
      "30 0.7233601212501526 51.875 42.5\n",
      "40 0.7125394344329834 51.875 42.5\n"
     ]
    }
   ],
   "source": [
    "# model = Net()\n",
    "# model.to(device)\n",
    "\n",
    "model = LSTM(input_dim=1, hidden_dim=100, batch_size=batch_size, output_dim=6, num_layers=2)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()  # expects ouputs from LogSoftmax\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "epochs = 50\n",
    "# Loop over the data\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    # Loop over each subset of data\n",
    "    for d,t in train_loader:\n",
    "\n",
    "        # Zero out the optimizer's gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "        d = d.view((65536,-1,1))\n",
    "        # Make a prediction based on the model\n",
    "        outputs = model(d)\n",
    "        \n",
    "        # print(\"output_shape: \", outputs.shape)  \n",
    "        # print(\"t: \", t.shape)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs,t) \n",
    "\n",
    "        # Use backpropagation to compute the derivative of the loss with respect to the parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Use the derivative information to update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    # After every 10th epoch, compute the test set accuracy\n",
    "    if epoch%10==0:\n",
    "        total=0.\n",
    "        correct=0.\n",
    "        # Loop over all the test examples and accumulate the number of correct results in each batch\n",
    "        for d,t in test_loader:\n",
    "            \n",
    "            d = d.view((65536,-1,1))\n",
    "            outputs = model(d)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += float(t.size(0))\n",
    "            correct += float((predicted==t).sum())\n",
    "        total_train = 0\n",
    "        correct_train = 0\n",
    "        for d,t in train_loader:\n",
    "\n",
    "            d = d.view((65536,-1,1))\n",
    "\n",
    "            outputs = model(d)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total_train += float(t.size(0))\n",
    "            correct_train += float((predicted==t).sum())\n",
    "        \n",
    "        # Print the epoch, the training loss, and the test set accuracy.\n",
    "        train_accs.append(100.*correct_train/total_train)\n",
    "        test_accs.append(100.*correct/total)\n",
    "\n",
    "        print(epoch,loss.item(),train_accs[-1],test_accs[-1])\n",
    "\n",
    "\n",
    "model.eval()\n",
    "X_test = X_test.view((65536,-1,1))\n",
    "y_pred = np.argmax(model(X_test).cpu().detach(),axis=1)\n",
    "y_test_cpu = y_test.cpu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bk4ops6U9bZK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNNB_fouroptions_Audio_classifier (4).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
